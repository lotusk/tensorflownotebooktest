{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified notMNIST_large.tar.gz\n",
      "Found and verified notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "url = 'http://yaroslavvb.com/upload/notMNIST/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if not os.path.exists(filename):\n",
    "    filename, _ = urllib.urlretrieve(url + filename, filename)\n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print 'Found and verified', filename\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['notMNIST_large/A', 'notMNIST_large/B', 'notMNIST_large/C', 'notMNIST_large/D', 'notMNIST_large/E', 'notMNIST_large/F', 'notMNIST_large/G', 'notMNIST_large/H', 'notMNIST_large/I', 'notMNIST_large/J']\n",
      "['notMNIST_small/A', 'notMNIST_small/B', 'notMNIST_small/C', 'notMNIST_small/D', 'notMNIST_small/E', 'notMNIST_small/F', 'notMNIST_small/G', 'notMNIST_small/H', 'notMNIST_small/I', 'notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notMNIST_large/A',\n",
       " 'notMNIST_large/B',\n",
       " 'notMNIST_large/C',\n",
       " 'notMNIST_large/D',\n",
       " 'notMNIST_large/E',\n",
       " 'notMNIST_large/F',\n",
       " 'notMNIST_large/G',\n",
       " 'notMNIST_large/H',\n",
       " 'notMNIST_large/I',\n",
       " 'notMNIST_large/J']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['notMNIST_small/A',\n",
       " 'notMNIST_small/B',\n",
       " 'notMNIST_small/C',\n",
       " 'notMNIST_small/D',\n",
       " 'notMNIST_small/E',\n",
       " 'notMNIST_small/F',\n",
       " 'notMNIST_small/G',\n",
       " 'notMNIST_small/H',\n",
       " 'notMNIST_small/I',\n",
       " 'notMNIST_small/J']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_folders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling notMNIST_large/A.pickle.\n",
      "notMNIST_large/A\n",
      "('Could not read:', 'notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png', ':', IOError(\"cannot identify image file <open file 'notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png', mode 'rb' at 0x10debced0>\",), \"- it's ok, skipping.\")\n",
      "('Could not read:', 'notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png', ':', IOError(\"cannot identify image file <open file 'notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png', mode 'rb' at 0x10a475ae0>\",), \"- it's ok, skipping.\")\n",
      "('Could not read:', 'notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png', ':', IOError(\"cannot identify image file <open file 'notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png', mode 'rb' at 0x10debced0>\",), \"- it's ok, skipping.\")\n",
      "('Full dataset tensor:', (52912, 28, 28))\n",
      "('Mean:', -0.12824316)\n",
      "('Standard deviation:', 0.44310907)\n",
      "Pickling notMNIST_large/B.pickle.\n",
      "notMNIST_large/B\n",
      "('Could not read:', 'notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png', ':', IOError(\"cannot identify image file <open file 'notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png', mode 'rb' at 0x10a475ae0>\",), \"- it's ok, skipping.\")\n",
      "('Full dataset tensor:', (52912, 28, 28))\n",
      "('Mean:', -0.0075629009)\n",
      "('Standard deviation:', 0.4544872)\n",
      "Pickling notMNIST_large/C.pickle.\n",
      "notMNIST_large/C\n",
      "('Full dataset tensor:', (52912, 28, 28))\n",
      "('Mean:', -0.14225811)\n",
      "('Standard deviation:', 0.43980625)\n",
      "Pickling notMNIST_large/D.pickle.\n",
      "notMNIST_large/D\n",
      "('Could not read:', 'notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png', ':', IOError(\"cannot identify image file <open file 'notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png', mode 'rb' at 0x10a475ae0>\",), \"- it's ok, skipping.\")\n",
      "('Full dataset tensor:', (52912, 28, 28))\n",
      "('Mean:', -0.057366688)\n",
      "('Standard deviation:', 0.45564321)\n",
      "Pickling notMNIST_large/E.pickle.\n",
      "notMNIST_large/E\n",
      "('Full dataset tensor:', (52912, 28, 28))\n",
      "('Mean:', -0.069898993)\n",
      "('Standard deviation:', 0.45294195)\n",
      "Pickling notMNIST_large/F.pickle.\n",
      "notMNIST_large/F\n",
      "('Full dataset tensor:', (52912, 28, 28))\n",
      "('Mean:', -0.12558331)\n",
      "('Standard deviation:', 0.44708964)\n",
      "Pickling notMNIST_large/G.pickle.\n",
      "notMNIST_large/G\n",
      "('Full dataset tensor:', (52912, 28, 28))\n",
      "('Mean:', -0.094581351)\n",
      "('Standard deviation:', 0.44623983)\n",
      "Pickling notMNIST_large/H.pickle.\n",
      "notMNIST_large/H\n",
      "('Full dataset tensor:', (52912, 28, 28))\n",
      "('Mean:', -0.068522058)\n",
      "('Standard deviation:', 0.45423177)\n",
      "Pickling notMNIST_large/I.pickle.\n",
      "notMNIST_large/I\n",
      "('Full dataset tensor:', (52912, 28, 28))\n",
      "('Mean:', 0.03078625)\n",
      "('Standard deviation:', 0.46889907)\n",
      "Pickling notMNIST_large/J.pickle.\n",
      "notMNIST_large/J\n",
      "('Full dataset tensor:', (52911, 28, 28))\n",
      "('Mean:', -0.15335836)\n",
      "('Standard deviation:', 0.44365644)\n",
      "Pickling notMNIST_small/A.pickle.\n",
      "notMNIST_small/A\n",
      "('Could not read:', 'notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png', ':', IOError(\"cannot identify image file <open file 'notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png', mode 'rb' at 0x10debced0>\",), \"- it's ok, skipping.\")\n",
      "('Full dataset tensor:', (1873, 28, 28))\n",
      "('Mean:', -0.13255553)\n",
      "('Standard deviation:', 0.4450196)\n",
      "Pickling notMNIST_small/B.pickle.\n",
      "notMNIST_small/B\n",
      "('Full dataset tensor:', (1873, 28, 28))\n",
      "('Mean:', 0.005356085)\n",
      "('Standard deviation:', 0.45711532)\n",
      "Pickling notMNIST_small/C.pickle.\n",
      "notMNIST_small/C\n",
      "('Full dataset tensor:', (1873, 28, 28))\n",
      "('Mean:', -0.1415206)\n",
      "('Standard deviation:', 0.44269031)\n",
      "Pickling notMNIST_small/D.pickle.\n",
      "notMNIST_small/D\n",
      "('Full dataset tensor:', (1873, 28, 28))\n",
      "('Mean:', -0.049216662)\n",
      "('Standard deviation:', 0.45975891)\n",
      "Pickling notMNIST_small/E.pickle.\n",
      "notMNIST_small/E\n",
      "('Full dataset tensor:', (1873, 28, 28))\n",
      "('Mean:', -0.05991479)\n",
      "('Standard deviation:', 0.45734963)\n",
      "Pickling notMNIST_small/F.pickle.\n",
      "notMNIST_small/F\n",
      "('Could not read:', 'notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png', ':', IOError(\"cannot identify image file <open file 'notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png', mode 'rb' at 0x10a475ae0>\",), \"- it's ok, skipping.\")\n",
      "('Full dataset tensor:', (1873, 28, 28))\n",
      "('Mean:', -0.11821133)\n",
      "('Standard deviation:', 0.45226094)\n",
      "Pickling notMNIST_small/G.pickle.\n",
      "notMNIST_small/G\n",
      "('Full dataset tensor:', (1872, 28, 28))\n",
      "('Mean:', -0.092550278)\n",
      "('Standard deviation:', 0.44900584)\n",
      "Pickling notMNIST_small/H.pickle.\n",
      "notMNIST_small/H\n",
      "('Full dataset tensor:', (1872, 28, 28))\n",
      "('Mean:', -0.058689252)\n",
      "('Standard deviation:', 0.45875895)\n",
      "Pickling notMNIST_small/I.pickle.\n",
      "notMNIST_small/I\n",
      "('Full dataset tensor:', (1872, 28, 28))\n",
      "('Mean:', 0.052645069)\n",
      "('Standard deviation:', 0.47189355)\n",
      "Pickling notMNIST_small/J.pickle.\n",
      "notMNIST_small/J\n",
      "('Full dataset tensor:', (1872, 28, 28))\n",
      "('Mean:', -0.15168911)\n",
      "('Standard deviation:', 0.44801357)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "  for image_index, image in enumerate(image_files):\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (ndimage.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[image_index, :, :] = image_data\n",
    "    except IOError as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  num_images = image_index + 1\n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "        \n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "  dataset_names = []\n",
    "  for folder in data_folders:\n",
    "    set_filename = folder + '.pickle'\n",
    "    dataset_names.append(set_filename)\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "      # You may override by setting force=True.\n",
    "      print('%s already present - Skipping pickling.' % set_filename)\n",
    "    else:\n",
    "      print('Pickling %s.' % set_filename)\n",
    "      dataset = load_letter(folder, min_num_images_per_class)\n",
    "      try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "      except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "  return dataset_names\n",
    "\n",
    "train_datasets = maybe_pickle(train_folders, 45000)\n",
    "test_datasets = maybe_pickle(test_folders, 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['extract']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e74f5d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngiAIgiC4/H/VKhac2HsOtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e878b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample=pickle.load(open(train_datasets[3]))\n",
    "plt.imshow(sample[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training:', (200000, 28, 28), (200000,))\n",
      "('Validation:', (10000, 28, 28), (10000,))\n",
      "('Testing:', (10000, 28, 28), (10000,))\n"
     ]
    }
   ],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "  num_classes = len(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):       \n",
    "    try:\n",
    "      with open(pickle_file, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "test_size = 10000\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(133)\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (200000, 28, 28) (200000,)\n",
      "Validation (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "\n",
    "valid_dataset = train_dataset[:valid_size,:,:]\n",
    "valid_labels = train_labels[:valid_size]\n",
    "train_dataset = train_dataset[valid_size:valid_size+train_size,:,:]\n",
    "train_labels = train_labels[valid_size:valid_size+train_size]\n",
    "print 'Training', train_dataset.shape, train_labels.shape\n",
    "print 'Validation', valid_dataset.shape, valid_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadresult=pickle.load(open('notMNIST.pickle','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_dataset=_60['train_dataset']\n",
    "train_labels=loadresult['train_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 690800441\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print 'Compressed pickle size:', statinfo.st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.fit(train_dataset,train_labels)\n",
    "test_dataset.shape\n",
    "# train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_dataset=train_dataset.reshape(200000,28*28,)\n",
    "test_dataset=test_dataset.reshape(10000,28*28,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset=loadresult['test_dataset']\n",
    "test_labels=loadresult['test_labels']\n",
    "valid_dataset=loadresult['valid_dataset']\n",
    "valid_labels=loadresult['valid_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape\n",
    "clf.fit(train_dataset,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18724, 784)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset=test_dataset.reshape(18724,28*28,)\n",
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89129999999999998"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_dataset,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 9, 6, ..., 1, 9, 8], dtype=int32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18694</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18695</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18696</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18697</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18698</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18699</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18700</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18701</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18702</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18703</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18704</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18705</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18706</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18707</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18708</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18709</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18710</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18711</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18712</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18713</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18714</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18715</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18716</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18717</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18718</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18719</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18720</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18721</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18722</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18723</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18724 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pre  y\n",
       "0        7  3\n",
       "1        9  9\n",
       "2        6  6\n",
       "3        0  0\n",
       "4        1  1\n",
       "5        1  1\n",
       "6        2  2\n",
       "7        5  5\n",
       "8        5  5\n",
       "9        8  8\n",
       "10       2  2\n",
       "11       1  1\n",
       "12       7  7\n",
       "13       0  0\n",
       "14       3  3\n",
       "15       3  3\n",
       "16       9  8\n",
       "17       1  1\n",
       "18       0  7\n",
       "19       9  9\n",
       "20       2  2\n",
       "21       5  5\n",
       "22       4  4\n",
       "23       4  4\n",
       "24       5  5\n",
       "25       9  8\n",
       "26       2  2\n",
       "27       4  1\n",
       "28       1  1\n",
       "29       0  0\n",
       "...    ... ..\n",
       "18694    9  9\n",
       "18695    8  8\n",
       "18696    9  9\n",
       "18697    5  5\n",
       "18698    1  1\n",
       "18699    1  1\n",
       "18700    6  6\n",
       "18701    9  9\n",
       "18702    2  2\n",
       "18703    8  8\n",
       "18704    2  2\n",
       "18705    3  3\n",
       "18706    3  8\n",
       "18707    2  2\n",
       "18708    7  7\n",
       "18709    5  5\n",
       "18710    7  7\n",
       "18711    8  8\n",
       "18712    4  4\n",
       "18713    2  2\n",
       "18714    4  4\n",
       "18715    0  0\n",
       "18716    6  6\n",
       "18717    4  4\n",
       "18718    7  7\n",
       "18719    3  3\n",
       "18720    3  1\n",
       "18721    1  1\n",
       "18722    9  9\n",
       "18723    8  8\n",
       "\n",
       "[18724 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"pre\":_86,\"y\":test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18724, 2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_88.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16713, 2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_88[_88['pre'] ==_88['y']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8925977355265969"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16713/18724.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
